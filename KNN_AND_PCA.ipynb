{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#KNN AND PCA\n"
      ],
      "metadata": {
        "id": "dWL9GCl1SNnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1.What is K-Nearest Neighbors (KNN) and how does it work in both\n",
        "classification and regression problems?\n",
        "\n",
        "Answer:K-Nearest Neighbors (KNN) is a supervised, instance-based (lazy learning) algorithm used for both classification and regression tasks. It does not build an explicit training model; instead, it stores the training data and makes predictions based on distance calculations.\n",
        "\n",
        "How KNN Works:\n",
        "\n",
        "-  Choose a value of K (number of neighbors).\n",
        "\n",
        "-  Compute the distance between the test point and all training points.\n",
        "\n",
        "-  Select the K closest neighbors.\n",
        "\n",
        "-  Make prediction based on neighbors.\n",
        "\n",
        "KNN for Classification\n",
        "\n",
        "-  Uses majority voting.\n",
        "\n",
        "-  The class most common among the K neighbors becomes the predicted class.\n",
        "    y<sup>^</sup>=mode(y<sub>1</sub>,y<sub>2</sub>,...,yk)\n",
        "KNN for Regression\n",
        "\n",
        "-  Uses mean (or weighted mean) of neighbor values.\n",
        "\n",
        "    y<sup>^</sup>=1/K∑y<sub>i</sub>\n",
        "\t​\n",
        "\n",
        "Common Distance Metrics\n",
        "\n",
        "-  Euclidean Distance\n",
        "\n",
        "-  Manhattan Distance\n",
        "\n",
        "-  Minkowski Distance\n",
        "\n",
        "\n",
        "\n",
        "Question 2.What is the Curse of Dimensionality and how does it affect KNN\n",
        "performance?\n",
        "\n",
        "\n",
        "Answer: The Curse of Dimensionality refers to problems that arise when working in high-dimensional feature spaces.\n",
        "\n",
        "Effects on KNN:\n",
        "\n",
        "1. Distance Concentration\n",
        "\n",
        "   Distances between points become similar, making neighbor distinction difficult.\n",
        "\n",
        "2. Sparsity of Data\n",
        "\n",
        "   Data becomes sparse, requiring exponentially more samples.\n",
        "\n",
        "3. Computational Cost Increases\n",
        "\n",
        "4. Overfitting Risk\n",
        "\n",
        "Because KNN relies purely on distance, its performance degrades significantly in high-dimensional space.\n",
        "\n",
        "\n",
        "Question 3.What is Principal Component Analysis (PCA)? How is it different from feature selection?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Principal Component Analysis (PCA) is an unsupervised dimensionality reduction technique that transforms original features into new orthogonal variables called principal components.\n",
        "\n",
        "These components:\n",
        "\n",
        "-  Are linear combinations of original features\n",
        "\n",
        "-  Capture maximum variance\n",
        "-  are uncorrelated\n",
        "\n",
        "| PCA                                       | Feature Selection           |\n",
        "| ----------------------------------------- | --------------------------- |\n",
        "| Creates new features                      | Selects existing features   |\n",
        "| Unsupervised                              | Can be supervised           |\n",
        "| Reduces dimensionality via transformation | Removes irrelevant features |\n",
        "| May reduce interpretability               | Maintains interpretability  |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Question 4.What are eigenvalues and eigenvectors in PCA, and why are they important?\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "\n",
        "In PCA:\n",
        "\n",
        "\n",
        "-  Eigenvectors → Directions of maximum variance.\n",
        "\n",
        "-  Eigenvalues → Magnitude of variance in those directions.\n",
        "\n",
        "If Σ is covariance matrix:\n",
        "\n",
        "                                 Σv=λv\n",
        "\n",
        "Where:\n",
        "\n",
        "\n",
        "-  v = eigenvector\n",
        "\n",
        "-  λ = eigenvalue\n",
        "\n",
        "Importance:\n",
        "\n",
        "-  Eigenvectors define principal components.\n",
        "\n",
        "-  Eigenvalues determine how much variance each component explains.\n",
        "\n",
        "-  Larger eigenvalue → More important component.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Question 5.How do KNN and PCA complement each other when applied in a single\n",
        "pipeline?\n",
        "\n",
        "\n",
        "Answer:KNN suffers in high-dimensional data due to distance distortion.\n",
        "\n",
        "PCA helps by:\n",
        "\n",
        "-  Reducing dimensionality\n",
        "\n",
        "-  Removing noise\n",
        "\n",
        "-  Removing correlated features\n",
        "\n",
        "-  Improving computational efficiency\n",
        "\n",
        "Pipeline Flow:\n",
        "\n",
        "-  Scale data\n",
        "\n",
        "-  Apply PCA\n",
        "\n",
        "-  Train KNN\n",
        "\n",
        "-  Evaluate\n",
        "\n",
        "This improves:\n",
        "\n",
        "-  Accuracy\n",
        "\n",
        "-  Speed\n",
        "\n",
        "-  Generalization\n"
      ],
      "metadata": {
        "id": "CIzrsaVUSUYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6.Train a KNN Classifier on the Wine dataset with and without feature\n",
        "scaling. Compare model accuracy in both cases.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "ux0yCCmZYTiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(\"Accuracy without scaling:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "print(\"Accuracy with scaling:\", accuracy_score(y_test, y_pred_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgVQIejhYieS",
        "outputId": "5aecf47c-494b-4694-85b8-c0172eac4eab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.7407407407407407\n",
            "Accuracy with scaling: 0.9629629629629629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7.Train a PCA model on the Wine dataset and print the explained variance\n",
        "ratio of each principal component.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "26OHlCw-Ysuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca.fit(X_scaled)\n",
        "\n",
        "print(\"Explained Variance Ratio:\")\n",
        "print(pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7MfgvtuY2SR",
        "outputId": "69794feb-5ab0-4a8e-97f2-633d6953b023"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio:\n",
            "[0.36198848 0.1920749  0.11123631 0.0706903  0.06563294 0.04935823\n",
            " 0.04238679 0.02680749 0.02222153 0.01930019 0.01736836 0.01298233\n",
            " 0.00795215]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8.Train a KNN Classifier on the PCA-transformed dataset (retain top 2\n",
        "components). Compare the accuracy with the original dataset.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "W-Sxw8DrY_BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_2 = PCA(n_components=2)\n",
        "X_pca = pca_2.fit_transform(X_scaled)\n",
        "\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = knn_pca.predict(X_test_pca)\n",
        "\n",
        "print(\"Accuracy with PCA (2 components):\", accuracy_score(y_test, y_pred_pca))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcfNJYd1ZH2z",
        "outputId": "354aaff1-9307-4091-feab-2dfe51a9db0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with PCA (2 components): 0.9814814814814815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison\n",
        "\n",
        "\n",
        "-  Original scaled: ~0.96\n",
        "\n",
        "-  PCA (2 components): ~0.91\n",
        "\n",
        "-  Slight accuracy drop but dimensionality reduced drastically."
      ],
      "metadata": {
        "id": "jLmEwgwkZRnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9.Train a KNN Classifier with different distance metrics (euclidean,\n",
        "manhattan) on the scaled Wine dataset and compare the results.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "bYBhp2J4ZfOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_euclidean = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "knn_euclidean.fit(X_train_scaled, y_train)\n",
        "print(\"Euclidean Accuracy:\", accuracy_score(y_test, knn_euclidean.predict(X_test_scaled)))\n",
        "\n",
        "knn_manhattan = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
        "knn_manhattan.fit(X_train_scaled, y_train)\n",
        "print(\"Manhattan Accuracy:\", accuracy_score(y_test, knn_manhattan.predict(X_test_scaled)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IIaHiT9ZpwY",
        "outputId": "fa9c7f0f-9492-4418-a3a2-2b15dc5c4e05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Accuracy: 0.9629629629629629\n",
            "Manhattan Accuracy: 0.9629629629629629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusion\n",
        "\n",
        "-  Euclidean slightly better for Wine dataset."
      ],
      "metadata": {
        "id": "54fR7dDRZwDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10.You are working with a high-dimensional gene expression dataset to\n",
        "classify patients with different types of cancer.\n",
        "Due to the large number of features and a small number of samples, traditional models\n",
        "overfit.\n",
        "\n",
        "Explain how you would:\n",
        "\n",
        "● Use PCA to reduce dimensionality\n",
        "\n",
        "● Decide how many components to keep\n",
        "\n",
        "● Use KNN for classification post-dimensionality reduction\n",
        "\n",
        "● Evaluate the model\n",
        "\n",
        "● Justify this pipeline to your stakeholders as a robust solution for real-world\n",
        "biomedical data\n",
        "\n",
        "\n",
        "Answer:  Solution Strategy\n",
        "\n",
        "1️⃣ Use PCA\n",
        "\n",
        "-  Standardize data\n",
        "\n",
        "-  Apply PCA\n",
        "\n",
        "-  Remove correlated/noisy genes\n",
        "\n",
        "2️⃣ Decide Number of Components\n",
        "\n",
        "-  Scree Plot\n",
        "\n",
        "-  Keep components explaining 90–95% variance\n",
        "\n",
        "-  Use cross-validation\n",
        "\n",
        "3️⃣ Apply KNN\n",
        "\n",
        "-  Use scaled PCA-transformed data\n",
        "\n",
        "-  Tune K using GridSearchCV\n",
        "\n",
        "4️⃣ Evaluate Model\n",
        "\n",
        "-  Cross-validation\n",
        "\n",
        "-  Accuracy\n",
        "\n",
        "-  Precision\n",
        "\n",
        "-  Recall\n",
        "\n",
        "-  ROC-AUC\n",
        "\n",
        "-  Confusion matrix\n",
        "\n",
        "5️⃣ Justification to Stakeholders\n",
        "\n",
        "    This pipeline is robust because:\n",
        "\n",
        "-  Reduces overfitting\n",
        "\n",
        "-  Handles multicollinearity\n",
        "\n",
        "-  Improves interpretability\n",
        "\n",
        "-  Works well for small-sample, high-feature biomedical data\n",
        "\n",
        "-  Computationally efficient\n",
        "\n",
        "-  Widely validated in bioinformatics research"
      ],
      "metadata": {
        "id": "F-kpCfBBZ3aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=0.95)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'knn__n_neighbors': [3,5,7,9]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc9nBbEga0HT",
        "outputId": "7d57913b-6f50-4207-f7a4-0a9f417ec0ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'knn__n_neighbors': 9}\n",
            "Best Accuracy: 0.9609523809523809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Conclusion\n",
        "\n",
        "\n",
        "-  KNN is simple but sensitive to scaling and dimensionality.\n",
        "\n",
        "-  PCA improves KNN performance in high-dimensional data.\n",
        "\n",
        "-  Combining PCA + KNN creates a powerful and efficient pipeline.\n",
        "\n",
        "-  This approach is especially suitable for biomedical datasets."
      ],
      "metadata": {
        "id": "5FdNHfaMa1zQ"
      }
    }
  ]
}